{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用 mallet 训练 LDA的示例代码"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "### 原始文件\n",
    "**raw.txt**: 原始数据文件。每一行是一篇文章，已经经过了分词处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "： 海清 密会 小沈阳 聚餐 男方 当街 提 裤子 ,....\r\n",
      "大越野 ss2 ： 赛车 再 拖后腿 魏红杰 深谋远虑 , 　....\r\n",
      "年 国军 冬季 大 反攻 蒋公 总结 , 蒋介石 关于....\r\n",
      "姐 麦明诗 不在意 走 光 整容 说 : 牙 都....\r\n",
      "： 创业板 或 逐步 进入 业绩 兑现 期 , [....\r\n",
      "学 摄影 ： 用 ps 打造出 手绘 特效 照片 ,....\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 6 raw.txt | awk '{ print $2\" \"$3\" \"$4\" \"$5\" \"$6\" \"$7\" \"$8\" \"$9\" \"$10\" \"$11\"....\" }'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "### 字典文件\n",
    "**words.dict**: 有效词的词典。 格式： id word other-info "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1`记者`302819\r\n",
      "2`中国`262746\r\n",
      "3`情况`243587\r\n",
      "4`今年`235291\r\n",
      "5`问题`231584\r\n",
      "6`时间`230710\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 6 words.dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* * *\n",
    "###  mallet的输入文本\n",
    "将原始文件转换成mallet能接受的输入文本: **examples.data**\n",
    "\n",
    "输入文本的格式有[详细的说明](http://mallet.cs.umass.edu/import.php):\n",
    ">the `first` token of each line (whitespace delimited, with optional comma) becomes the instance name, the `second` token becomes the label, and `all additional` text on the line is interpreted as a sequence of word tokens.\n",
    "\n",
    "需要注意的是，如果用于LDA的输入文本，必须是**a sequence of word tokens**而不是**a vector of feature/value pairs**:\n",
    ">--keep-sequence. This option preserves the document as a sequence of word features, rather than a vector of word feature counts. Use this option for sequence labeling tasks. The MALLET topic modeling toolkit also requires feature sequences rather than feature vectors.\n",
    "\n",
    "为了避免中文可能导致的问题，我将所有的词都转换成了对应的词id。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 lab 2136 48210 75483 46484 14675 12958 24227 1907 6463 826 492 6808 83139 46484 5227 4142 569 7226 106102 1158 11826 4210 24856 1245 228684 50118 1 56848 6025 1766 13723 46484 48210 5502 3224 1611 1379 121 32784 1571 46484 1379 3856 1472 38953 2734 14206 42664 1537 1537 1907 6463 1027 3856 2353 3598 10533 1527 1006 3856 7409 1 177 2674 3856 2752 552 12331 3856 1217 2142 46484 2734 6025 15209 48210 38953 2734 25623 48210 204 5513 5269 3865 8986 533 3817 1632 3759 6775 310 21 6025 428 1379 34144 14675 143 2349 48210 348 64 577 26926 80932 463 53212 3887 14684 121 561 463 48210 26926 80932 986 71 3291 161 463 25515 2846 284 1033 2620 109746 333 2374 463 3402 1029 9276 25515 52893 2846 7016 2620 4602 333 19733 8347 7668 7927 1865 41088 8916 48210 3533 2872 31969 46484 12011 2820 47932 5161 3555 139 311 216966 139 3028 3606 9603 5615 374 7438 4821 14324 11834 3555 44 5787 1123 1664 3310 1402 1019 20545 2825 3187 676 7170 9603 10330 1663 1664 47932 1757 3114 1379 2960 20047 5615 15483 25019 76099 1083 7153 46484 2212 169876 721 2089 25376 16133 2020 26404 5187 7364 147964 2727 53 46484 17424 311 15636 433 93 13780 46484 1644 232 1099 2036 958 10582 2036 97 1150 13283 1150 40727 684 1245 163 34148\r\n",
      "2 lab 2 209750 9970 42044 76471 6388 2 143091 197 417 44939 2509 259883 22741 8149 4425 82045 21 1855 253 1616 3409 733 882 44939 30 3276 21779 417 44939 762 15466 10338 62538 56260 9469 894 4335 1293 1090 44939 1579 15596 116642 1375 9970 4456 2513 265 8753 9125 7881 325 325 406 42044 677 9970 21 44939 115441 178 44939 2384 5 1220 9 7103 187 78 733 44939 46 9970 21 3742 115441 1839 346 84102 7 602 1306 3492 26183 46400 15 9970 44854 8753 602 99 454 636 78 733 3225 355 1134 17 6 21890 623 406 21 44939 36507 265 27476 25279 21 117 1855 3490 57275 1616 30 253 8753 9125 86893 209750 396 18833 386 355 2029 9 5 265 56263 9 47813 9 253 8753 325 1439 900 1655 882 44939 2509 51714 16349 673 44939 762 1946 8753 44939 966 473\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 2 examples.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "### 用mallet导入数据\n",
    "使用`mallet import-file`导入输入文本。\n",
    "\n",
    "可以使用`mallet import-file --help`查看详细的使用方法。\n",
    "\n",
    "生成的**examples.mallet**是一个二进制文件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!mallet import-file --input examples.data --output examples.mallet --keep-sequence --token-regex '[a-z0-9]+'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "### LDA训练\n",
    "使用`mallet train-topics`进行LDA训练。\n",
    "\n",
    "使用`mallet train-topics --help`查看详细的使用方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!mallet train-topics --input examples.mallet --num-topics 50 --num-threads 1 --num-iterations 800 \\\n",
    "        --optimize-burn-in 200 --alpha 5 --beta 0.01 --optimize-interval 10 --output-state examples-topic-state.gz \\\n",
    "        --output-topic-keys examples_keys.txt --output-doc-topics examples_composition.txt --show-topics-interval 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "### LDA训练的结果\n",
    "\n",
    "####  Topic的效果 `examples_keys.txt`\n",
    "\n",
    "**topic-keys**文件中保存的是每个topic排名最前的词:\n",
    "> The filename in which to write the top words for each topic and any Dirichlet parameters.\n",
    "> The second number in each paragraph is the Dirichlet parameter for the topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\t0.04458\t55 60 2401 547 2118 147 395 94 1242 152 330 1025 1202 6536 994 1381 467 4470 3031 2218 \r\n",
      "1\t0.04353\t1586 518 2799 126 690 1375 1536 2297 4157 2025 54 527 3799 955 421 3623 2070 53 6414 1803 \r\n",
      "2\t0.06352\t32 305 20 496 309 2 55 393 12 14 85 112 114 129 303 642 45 6293 402 573 \r\n",
      "3\t0.02874\t5014 122 382 8804 2098 2062 2 8116 1390 267 7330 2555 9533 6490 1009 2219 4119 328 532 6081 \r\n",
      "4\t0.02526\t1406 11187 1109 36 237 21362 1690 1 13169 5774 12534 10171 9 3453 303 22811 9571 7991 2191 180 \r\n"
     ]
    }
   ],
   "source": [
    "!head -n 5 examples_keys.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这样看着不清楚，我需要将里面的id转换成词:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : 项目 建设 垃圾 工程 公园 城市 规划 环境 设施 中心 市民 生态 建筑 搬迁 改造 环保 道路 停车场 西安 城区\n",
      "1 : 事故 车辆 交警 安全 交通 驾驶 违法 运输 机动车 执法 发生 检查 爆炸 民警 有限公司 违法行为 整治 现场 火灾 天津\n",
      "2 : 企业 集团 公司 改革 产业 中国 项目 开发 市场 发展 技术 行业 计划 领域 生产 转型 未来 天然气 我国 运营\n",
      "3 : 抗战 历史 日本 日军 周年 战争 中国 抗日 胜利 上海 抗日战争 纪念 抗战胜利 神话 老人 和平 战场 故事 当年 中国人民\n",
      "4 : 食品 暴雨 天气 部分 地区 检出 检测 记者 积水 毫米 样品 大雨 出现 气温 生产 微商 批次 雨水 监测 严重\n",
      "5 : 工作 服务 建设 开展 推进 政府 农村 保障 社会 社区 创业 实施 记者 建立 资金 重点 改革 发展 就业 完善\n",
      "6 : 平台 互联网 服务 行业 市场 用户 模式 数据 提供 融资 产品 公司 企业 投资 领域 创业 电商 运营 客户 钉\n",
      "7 : 规定 信息 记者 相关 要求 服务 使用 办理 根据 发布 不得 情况 登记 广告 企业 管理 机构 单位 部门 其他\n",
      "8 : 现在 我的 大家 时间 起来 喜欢 最后 今天 朋友 事情 真的 后来 感觉 希望 工作 于是 出来 一起 当然 曾经\n",
      "9 : border td solid width top 1px 0px none 7px style padding left right bottom valign pt tr 王迅 资料 color\n",
      "10 : 周边 地铁 公交 车辆 记者 线路 交通 道路 出行 配套 公里 泰禾 乘客 市民 施工 号线 方向 公交车 时间 通行\n",
      "11 : 科学家 火星 细节 技术 李晨 研究 千足虫 地球 月球 人类 来自 敦煌 碎叶 余生 壁画 物种 范冰冰 方法 报道 ct\n",
      "12 : 拍摄 音乐 摄影 照片 侯孝贤 聂隐娘 电影 作品 拍 镜头 梅毒 故事 the 人物 摄影师 周韵 歌手 风格 少年 女人\n",
      "13 : 手机 支持 三星 设计 屏幕 接口 产品 像素 采用 功能 处理器 机身 方面 nbsp galaxy 系列 英寸 版 性能 摄像头\n",
      "14 : 中国 美国 日本 报道 俄罗斯 国家 政府 英国 全球 难民 政治 德国 泰国 亚洲 地区 亿美元 纽约 国际 法国 韩国\n",
      "15 : 市场 品牌 价格 产品 消费者 商品 购买 店 顾客 电缆 消费 蓝宝石 记者 商家 酒店 香港 购物中心 the 超市 门店\n",
      "16 : 亿元 上半年 今年 公司 增长 下降 同比 行业 业绩 记者 净利润 基金 万元 实现 同比增长 投资 增速 市场 规模 股\n",
      "17 : 高铁 銝 旅客 铁路 嚗 漣 扇 列车 餉 小时 沈阳 泉州 福厦 公里 賢 撟 漳州 丹东 城际 撣\n",
      "18 : 活动 文化 中国 记者 现场 举行 艺术 举办 国际 参加 展示 主题 今年 全国 希望 仪式 来自 了解 论坛 代表\n",
      "19 : rdquo ldquo 台湾 公益 彩票 东莞 选民 教授 人民 香港 朝中社 选区 长江实业 担任 大选 大陆 狄仁杰 委员会 反对党 议员\n",
      "20 : 学校 学生 教育 老师 家长 小学 孩子 幼儿园 开学 高校 教师 考试 大学 新生 招生 记者 校园 报名 学习 同学\n",
      "21 : 事项 重大 公告 临时停牌 保养 汽车 经销商 费用 4s店 现车 维修 万元 价格 款 左右 询价 上门 gt 店 车型\n",
      "22 : 记者 发现 现场 附近 工作人员 市民 车 一辆 民警 女士 告诉 司机 一名 男子 下午 上午 老人 介绍 情况 昨日\n",
      "23 : 语言 形态 形式 关系 意义 概念 事实 认知 内容 理解 先生 作者 体 属性 诗歌 道德 逻辑 存在 赠与 诗\n",
      "24 : 小区 社区 物业 上海 业主 装修 长沙 电梯 楼 公司 养老 居民 创客 空间 物业管理 更换 房子 别墅 图书馆 住户\n",
      "25 : 发展 企业 项目 亿元 建设 产业 经济 江门 合作 打造 城市 实现 投资 创新 推进 省 工业 家 对接 国家\n",
      "26 : 使用 选择 设计 效果 不同 大家 内容 部分 工具 系统 设置 位置 体验 时间 其他 细节 模式 起来 图片 下面\n",
      "27 : 比赛 球队 球员 赛季 曼联 冠军 加盟 对手 球迷 转会 球 火箭 皇马 科比 拜仁 北京时间 联赛 世锦赛 皮萨罗 获得\n",
      "28 : 公司 上市公司 亿元 股东 公告 关于 重组 股份 股权 股票 资产 交易 股 非公开发行 票 审议 议案 股份有限公司 股东大会 董事会\n",
      "29 : 工作 干部 责任 领导 落实 要求 建设 问题 群众 监督 会议 教育 基层 加强 政治 制度 书记 坚持 安全生产 部门\n",
      "30 : 用户 苹果 手机 产品 iphone 智能 功能 公司 设备 应用 推出 智能手机 网站 6s 腾讯 乔布斯 apple 电视 手表 硬盘\n",
      "31 : 警方 男子 妻子 女子 电话 对方 民警 丈夫 发现 两人 李某 女士 一名 双方 报警 医院 派出所 犯罪嫌疑人 案件 手机\n",
      "32 : 肌肤 头发 种姓 查看 演唱会 皮肤 米尔纳 工资 加班 产品 印度 大图 上海 面膜 梁家辉 olivia 乌托邦 饰 舞台 成员\n",
      "33 : 电影 观众 导演 网友 演员 影片 票房 粉丝 角色 节目 饰演 主演 娱乐 微博 电视剧 剧中 这部 拍 视频 播出\n",
      "34 : td title 深圳 旧址 align right 纪念馆 红色旅游 烈士 个人 大米 遗址 金立 拍卖 纪念 红色 型 烈士陵园 财富 北京\n",
      "35 : 市场 股市 下跌 美元 指数 投资者 反弹 中国 继续 上涨 持续 美联储 跌幅 月份 资金 投资 跌 股票 行情 流动性\n",
      "36 : 保险 村民 赔偿 万元 保险公司 公司 损失 保障 法院 调解 村里 洛阳 清 保费 双方 专车 基因 etc 长寿 房屋\n",
      "37 : 调研 张国焘 毛泽东 sz 县委书记 中共 中央 烟台 周恩来 股 博古 日至 会议 定边 张闻天 朱雀 东江纵队 机构 投资 泽熙\n",
      "38 : 银行 贷款 住房 万元 政策 住宅 北京 套 最低 楼市 记者 购买 利率 房价 比例 业务 客户 公积金贷款 首付 降息\n",
      "39 : 中国 作战 潜艇 美国 导弹 火箭炮 越南 歼 俄罗斯 装备 报道 飞机 核潜艇 王安 战略 型 区域 龟背 我国 系统\n",
      "40 : 医院 患者 医生 医疗 治疗 民营 手术 医疗机构 疾病 拍打 药物 河马 病人 公立医院 检查 北京市 狮子 执业 主任医师 慢性病\n",
      "41 : 阅兵 部队 方队 训练 官兵 本网 图片 受阅 参加 联合 代表 天安门 转载 负责 双拥 胡琏 战士 及时 任务 队员\n",
      "42 : 穿 时尚 搭配 照片 拍摄 何炅 造型 一组 超模 身材 自拍 头发 女神 nbsp 拍 婚纱 写真 身穿 性感 曝光\n",
      "43 : 案件 行为 法律 法院 法官 涉嫌 权力 调查 法庭 万元 犯罪 依法 司法 某某 官员 死刑 严重 规定 律师 组织\n",
      "44 : 车型 汽车 发动机 款 全新 新车 车 动力 品牌 方面 配置 新一代 设计 豪华 外观 丰田 推出 万元 搭载 四驱\n",
      "45 : 健康 食物 身体 导致 作用 含有 每天 症状 女性 蔬菜 维生素 疾病 注意 食用 人体 水 分钟 功能 喝 饮食\n",
      "46 : 孩子 父母 家庭 母亲 妈妈 儿子 儿童 女儿 帮助 女孩 爱心 子女 父亲 生活 家里 爸爸 男孩 老人 妻子 教育\n",
      "47 : 问题 情况 出现 中国 影响 进入 比如 其他 存在 更多 不能 是否 发现 选择 不同 方面 现在 最大 导致 根据\n",
      "48 : 胎儿 猪 怀孕 狗 脑壳 孕妇 动物 娃娃 陈妍希 攻 牙齿 孕期 子宫 肉 宝宝 桃花 骨头 鼻子 晒太阳 拉面\n",
      "49 : 旅游 游客 文化 这里 海洋 景区 当地 城市 历史 山 游 导游 休闲 保护 特色 亲子 旅行 每年 公里 洞头\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import codecs\n",
    "\n",
    "def load_vec_dict(vfile):\n",
    "    vdict = {}\n",
    "    for line in codecs.open(vfile, \"r\", \"utf8\"):\n",
    "        line = line.strip()\n",
    "        items = line.split(\"`\")\n",
    "        if len(items) < 2:\n",
    "            continue\n",
    "        vdict[int(items[0])] = items[1]\n",
    "    return vdict\n",
    "\n",
    "def print_topic_keys(tkfile, vdict):\n",
    "    for line in codecs.open(tkfile, \"r\", \"utf8\"):\n",
    "        items = line.split(\"\\t\")\n",
    "        topicid = items[0]\n",
    "        ids = items[2].split(\" \")\n",
    "        ids = ids[:-1]\n",
    "        words = [vdict.get(int(id)) for id in ids]\n",
    "        print topicid + \" : \" + \" \".join(words)\n",
    "\n",
    "vdict = load_vec_dict(\"words.dict\")\n",
    "print_topic_keys(\"examples_keys.txt\", vdict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 每篇文章关于Topic的分布 `examples_composition.txt`\n",
    "\n",
    "**doc-topics**保存的是每篇文章的Topic分布:\n",
    "> The filename in which to write the topic proportions per document, at the end of the iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\t1\t1.8710862416137548E-4\t1.8268029448505129E-4\t2.6660203127081136E-4\t1.2061353446059575E-4\t1.0600426781484946E-4\t4.3220776934051777E-4\t1.9949368676932172E-4\t4.458226657652823E-4\t0.21492698848282757\t1.0074355283481964E-5\t1.8906709220776387E-4\t5.164549796542017E-5\t1.0599858535676162E-4\t9.250077632081983E-5\t2.1863023532950842E-4\t1.151840866576433E-4\t2.1879961957341882E-4\t3.392818899873787E-5\t0.059143678021967815\t6.76591914659558E-5\t1.6336606230725803E-4\t3.3422424544119755E-5\t0.08011125397212848\t7.995486796415965E-5\t8.78745229395449E-5\t1.5915748457406072E-4\t0.01309693753539036\t8.695321730618228E-5\t8.269894375319518E-5\t2.1182513956066311E-4\t1.3241156671328898E-4\t0.03376089984861472\t4.463920307860546E-5\t0.13443187266673162\t3.871803131338747E-5\t1.5133103634966806E-4\t8.296260231016834E-5\t3.3164326943691246E-5\t1.1383334115769523E-4\t4.593339137625585E-5\t7.60248674107469E-5\t6.674010863701453E-5\t0.2728985423208539\t1.1521798938855096E-4\t7.108728108218255E-5\t1.317858624565444E-4\t0.06315400163890597\t0.05604729349224116\t0.06722293925066102\t1.5246999528314528E-4\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 1 examples_composition.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
